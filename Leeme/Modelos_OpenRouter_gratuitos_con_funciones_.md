

# **Análisis y Clasificación de Modelos Gratuitos de OpenRouter con Capacidad de Llamada a Herramientas**

## **Resumen Ejecutivo**

Este informe identifica, valida y clasifica los Modelos de Lenguaje Grandes (LLM) gratuitos disponibles en OpenRouter que soportan la llamada a herramientas (función de *function calling*), una capacidad fundamental para construir agentes inteligentes y automatizar flujos de trabajo. El análisis sintetiza especificaciones técnicas, evaluaciones oficiales y, crucialmente, comentarios de la comunidad para ofrecer una evaluación práctica de la "potencia" y la fiabilidad en el uso de herramientas de cada modelo en escenarios del mundo real.

Las principales recomendaciones incluyen Google Gemini 2.0 Flash Experimental, MoonshotAI Kimi K2 y DeepSeek V3 0324, que emergen como las opciones más potentes y fiables para diversas aplicaciones de llamada a herramientas. Mistral Devstral Small se destaca por su excelencia en tareas de agentes de codificación especializados.

Las observaciones de la comunidad revelan matices importantes, como los problemas de fiabilidad de DeepSeek R1 0528 en la llamada a funciones de múltiples turnos, a pesar de su impresionante rendimiento general. Esto subraya que el soporte explícito no siempre se traduce en una funcionalidad robusta en todos los escenarios prácticos.

## **Introducción: Navegando LLMs Gratuitos en OpenRouter para la Llamada a Herramientas**

OpenRouter funciona como una Interfaz de Programación de Aplicaciones (API) de inferencia unificada, simplificando el acceso a una amplia gama de LLMs de diversos proveedores a través de una interfaz única y estandarizada.1 Esta plataforma reduce significativamente la complejidad asociada con la gestión de múltiples APIs específicas de proveedores, facilitando la integración de modelos avanzados de inteligencia artificial en aplicaciones.

La llamada a herramientas, también conocida como uso de funciones, es una capacidad fundamental que extiende las funcionalidades de los LLMs más allá de la mera generación de texto. Permite que los modelos sugieran e interactúen de manera inteligente con herramientas externas, como APIs, bases de datos o funciones personalizadas, para realizar acciones específicas o recuperar información del mundo real.4 Esta característica es esencial para el desarrollo de agentes de IA sofisticados capaces de resolver problemas de forma autónoma, recuperar datos y automatizar flujos de trabajo complejos. La estandarización de OpenRouter de la interfaz de llamada a herramientas a través de los modelos compatibles es una ventaja clave, ya que facilita a los desarrolladores cambiar entre modelos o integrar múltiples herramientas sin una recodificación extensa.2

Un aspecto notable de la oferta de OpenRouter es la disponibilidad de modelos potentes, algunos con capacidades avanzadas como la llamada a herramientas, sin costo monetario directo.7 Esta accesibilidad elimina una barrera financiera significativa para desarrolladores e investigadores. Al hacer que las sofisticadas capacidades de llamada a herramientas sean accesibles sin una inversión inicial, OpenRouter fomenta la experimentación y la innovación generalizadas en la IA agéntica. Esto democratiza el panorama del desarrollo, permitiendo que equipos más pequeños, nuevas empresas o investigadores individuales prototipen y desplieguen aplicaciones avanzadas de IA que interactúan con el mundo real, algo que antes solo era factible para organizaciones con grandes recursos. Este enfoque acelera la adopción y la aplicación práctica de la IA más allá de las funcionalidades básicas de chat.

### **Metodología para la Identificación, Evaluación y Clasificación de Modelos**

La identificación de los modelos se realizó inicialmente filtrando el catálogo de OpenRouter para modelos "gratuitos" 7 y verificando con la documentación y las descripciones de los modelos que explícitamente indicaban soporte para "llamada a funciones" o "uso de herramientas".1

La evaluación de la "potencia" y la efectividad de la llamada a funciones de los modelos se llevó a cabo mediante un enfoque multifacético:

* **Capacidades Oficiales y Optimizaciones:** Se revisaron las afirmaciones del proveedor sobre la arquitectura del modelo (por ejemplo, MoE, recuento de parámetros), el tamaño de la ventana de contexto y las optimizaciones específicas para tareas agénticas, codificación o razonamiento.1  
* **Clasificación Interna de OpenRouter:** Se utilizó la clasificación propia de OpenRouter para la popularidad general del modelo y el rendimiento percibido 15 como un indicador inicial de utilidad general.  
* **Evaluaciones Independientes:** Se incorporaron resultados de evaluaciones reconocidas como SWE-Bench, LiveCodeBench, GPQA, Tau2 y AceBench, particularmente aquellas relacionadas con el uso de herramientas o capacidades agénticas.11  
* **Informes y Discusiones de la Comunidad:** De manera crucial, se sintetizaron comentarios cualitativos y cuantitativos de comunidades de desarrolladores (por ejemplo, Reddit, blogs especializados) para validar el rendimiento en el mundo real, identificar limitaciones prácticas y descubrir matices no capturados por las declaraciones oficiales.17 Este paso es fundamental para confirmar que los modelos "realmente funcionan con herramientas" según lo solicitado.

La clasificación final prioriza los modelos que demuestran capacidades de llamada a funciones robustas y fiables, considerando una visión holística de su inteligencia general, optimizaciones especializadas y efectividad validada en el mundo real, en lugar de depender únicamente del recuento de parámetros brutos o de evaluaciones generales.

## **Entendiendo la "Potencia" y la Llamada a Herramientas en LLMs**

### **Definición de Métricas Clave para Evaluar la Potencia del Modelo**

Para evaluar la potencia de un LLM, especialmente en el contexto de la llamada a herramientas, se consideran varias métricas fundamentales:

* **Recuento de Parámetros:** Representa el número de pesos y sesgos en una red neuronal, que a menudo se correlaciona con la capacidad de aprendizaje y la complejidad de un modelo. Para los modelos de Mezcla de Expertos (MoE) como Kimi K2 y DeepSeek, es importante distinguir entre los *parámetros totales* (el tamaño total del modelo) y los *parámetros activos* (el subconjunto utilizado por pasada de inferencia), lo que influye tanto en la capacidad como en la eficiencia computacional.7  
* **Ventana de Contexto:** Define la longitud máxima de entrada (y a veces de salida) que un modelo puede procesar en una sola interacción, medida en tokens.1 Una ventana de contexto más grande es vital para tareas agénticas complejas y de múltiples pasos, ya que permite al modelo retener más historial conversacional, esquemas de herramientas detallados y los resultados de llamadas a herramientas anteriores.  
* **Rendimiento en Evaluaciones (Benchmarks):** Las evaluaciones estandarizadas miden varios aspectos de la inteligencia del modelo. Para la llamada a funciones, las evaluaciones relevantes incluyen:  
  * **Razonamiento:** MMLU, GPQA.11  
  * **Codificación:** HumanEval, SWE-Bench, LiveCodeBench.11  
  * **Uso de Herramientas/Tareas Agénticas:** Tau2, AceBench 11, y evaluaciones especializadas como BFCL\_v3\_MultiTurn.22  
* **Rendimiento y Latencia:** Indicadores de rendimiento prácticos que reflejan la velocidad a la que un modelo genera respuestas (rendimiento en tokens por segundo) y el tiempo hasta el primer token (latencia).10 Estos son cruciales para aplicaciones en tiempo real.  
* **Capacidades Agénticas:** La capacidad inherente de un modelo para comprender, planificar y ejecutar tareas complejas de forma autónoma, a menudo orquestando múltiples llamadas a herramientas y razonando sobre resultados intermedios.11

### **Explicación de las Capacidades de Llamada a Funciones/Uso de Herramientas**

El mecanismo central de la llamada a funciones implica que el LLM identifique cuándo se necesita una función externa para satisfacer la solicitud de un usuario, y luego genere una llamada estructurada (por ejemplo, JSON) con los argumentos necesarios.4 Es fundamental comprender que el LLM

*no ejecuta* la herramienta directamente. En cambio, *sugiere* la llamada a la herramienta, que luego es ejecutada por la aplicación del usuario. Los resultados de esta ejecución se retroalimentan al LLM para su posterior procesamiento y generación de respuestas.4 Este diseño de "humano en el bucle" o "aplicación en el bucle" es fundamental para el funcionamiento del uso de herramientas.

OpenRouter estandariza este proceso de tres pasos (solicitud de inferencia con herramientas, ejecución de herramientas del lado del cliente, solicitud de inferencia con resultados de herramientas), asegurando una experiencia de API consistente en diferentes modelos subyacentes.2 Las capacidades avanzadas incluyen:

* **Llamada a Funciones Paralela:** El modelo puede sugerir múltiples llamadas a herramientas simultáneamente en un solo turno.6  
* **Llamada a Funciones Composicional:** El modelo puede encadenar múltiples llamadas a herramientas secuencialmente, razonando sobre los resultados de una llamada antes de realizar la siguiente.4 Esto es vital para flujos de trabajo agénticos complejos y de múltiples pasos.

Un análisis detallado revela que la "potencia" de un modelo en la llamada a herramientas va más allá de las evaluaciones brutas de su inteligencia general. Por ejemplo, modelos como DeepSeek R1 0528 obtienen puntuaciones altas en evaluaciones de inteligencia general 16 y soportan explícitamente la llamada a funciones.19 Sin embargo, los informes de la comunidad indican fallos significativos en la llamada a funciones de múltiples turnos para DeepSeek R1 0528\.22 Esta discrepancia indica que la inteligencia bruta o incluso el soporte declarado para la llamada a funciones no garantizan un rendimiento robusto para escenarios complejos y encadenados de uso de herramientas. La capacidad de un modelo para la llamada a funciones no se limita a su habilidad para generar una llamada correcta, sino a su fiabilidad en la

*secuenciación* de llamadas, el *razonamiento* sobre los resultados intermedios y el *mantenimiento del estado* a lo largo de múltiples turnos. Los modelos específicamente optimizados para "flujos de trabajo agénticos" (como Kimi K2 o Devstral Small) pueden ofrecer una "potencia" práctica superior para el uso de herramientas, incluso si sus evaluaciones generales no son las más altas, porque su entrenamiento se centra en estas interacciones matizadas. Esto significa que los desarrolladores deben mirar más allá de las evaluaciones principales y considerar las demandas específicas de su aplicación agéntica.

## **Análisis Detallado de Modelos Gratuitos de OpenRouter con Soporte para Llamada a Funciones**

La siguiente tabla presenta una visión general de los modelos gratuitos disponibles en OpenRouter que soportan la llamada a funciones, junto con sus especificaciones clave y fortalezas relevantes para esta capacidad.

### **Tabla 1: Modelos Gratuitos de OpenRouter con Capacidades de Llamada a Funciones**

| Modelo (Proveedor) | Arquitectura | Parámetros (Total/Activos) | Ventana de Contexto | Soporte Explícito FC | Costo OpenRouter | Fortalezas Clave (para FC) |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| Google: Gemini 2.0 Flash Experimental | N/A | N/A (3.83B tokens) | 1.05M tokens | Sí 7 | $0/M 7 | Optimizaciones agénticas, multimodal, velocidad, gran ventana de contexto 10 |

*(Nota: Los recuentos de parámetros para modelos no MoE o donde no se especifica el parámetro activo se refieren al tamaño general del modelo o al "token" como se indica en las fuentes. Las arquitecturas MoE se indican cuando se especifican parámetros totales/activos.)*

### **Google: Gemini 2.0 Flash Experimental (gratuito)**

Este modelo, proporcionado por Google, se distingue por su sustancial ventana de contexto de 1.05 millones de tokens 7, lo que lo hace altamente capaz para procesar entradas extensas y mantener largos historiales conversacionales. Al ser un modelo gratuito en OpenRouter, no genera costos de entrada ni de salida.7 Las descripciones oficiales resaltan sus "notables mejoras en la comprensión multimodal, las capacidades de codificación, el seguimiento de instrucciones complejas y la llamada a funciones".7 Está específicamente diseñado para ofrecer "experiencias agénticas más fluidas y robustas".10

En la clasificación interna de OpenRouter, Gemini 2.0 Flash ocupa una sólida segunda posición en uso de tokens 15, lo que indica su adopción generalizada y utilidad percibida en la plataforma. La retroalimentación de la comunidad, particularmente de discusiones en Reddit, es abrumadoramente positiva. Los usuarios elogian su "gran ventana de contexto, velocidad y multimodalidad", señalando que es "bastante fiable".17 A pesar de cierto escepticismo general en torno a los modelos Gemini, esta versión específica de Flash 2.0 se describe como "muy barata" (gratuita) y que realiza "un gran trabajo en las tareas cotidianas".17 Algunos usuarios incluso afirman que es "mejor que gpt4o latest" para sus necesidades específicas, enfatizando su sólida propuesta de valor.17 Se observa que las empresas lo consideran un "fuerte contendiente" basándose en el valor y el precio.17

Gemini 2.0 Flash Experimental se destaca como uno de los modelos gratuitos más potentes para la llamada a funciones. Su alta clasificación general en OpenRouter, combinada con mejoras explícitas para la llamada a funciones y una sólida validación comunitaria de su fiabilidad y velocidad prácticas, lo posicionan como una opción principal. La ventana de contexto excepcionalmente grande de 1.05M tokens es un activo significativo para escenarios complejos de uso de herramientas intensivos en datos. La discrepancia entre el sentimiento general de la comunidad hacia los modelos Gemini y la retroalimentación específica y positiva para Gemini 2.0 Flash Experimental en OpenRouter subraya que la percepción general de la marca o las evaluaciones más amplias pueden no reflejar con precisión el rendimiento de un modelo para características específicas en una plataforma particular. Para los desarrolladores, esto implica que la validación comunitaria en el mundo real y específica de las características en la plataforma de destino (OpenRouter para la llamada a funciones) es más valiosa que las opiniones generalizadas. Un modelo puede ser excepcionalmente "potente" para una aplicación de nicho, incluso si su reputación más amplia es mixta, lo que demuestra la importancia de profundizar en el rendimiento de casos de uso específicos.

### **MoonshotAI: Kimi K2 (gratuito)**

Kimi K2, de MoonshotAI, es un modelo de lenguaje de Mezcla de Expertos (MoE) a gran escala, con un impresionante billón de parámetros totales y 32 mil millones de parámetros activos por pasada de inferencia.7 Ofrece una sustancial ventana de contexto de 128K tokens 7 y está disponible de forma gratuita en OpenRouter.7 Un aspecto clave es su optimización explícita para "capacidades agénticas, incluyendo el uso avanzado de herramientas, el razonamiento y la síntesis de código".7 Ha demostrado excelencia en una amplia gama de evaluaciones, específicamente en codificación (LiveCodeBench, SWE-bench), razonamiento (ZebraLogic, GPQA) y tareas de uso de herramientas (Tau2, AceBench).7

Las discusiones de la comunidad refuerzan la fortaleza de Kimi K2, señalando su "increíble capacidad para seguir instrucciones y usar herramientas", que es precisamente para lo que fue optimizado.18 Su inteligencia agéntica se ve aún más evidenciada por su adopción en varias aplicaciones públicas destacadas en OpenRouter, muchas de las cuales son agentes de codificación como Kilo Code, Roo Code y OpenCode.11

Kimi K2 es un modelo altamente potente, específicamente diseñado y optimizado para capacidades agénticas y uso avanzado de herramientas. Su impresionante rendimiento en evaluaciones relevantes y el fuerte respaldo de la comunidad por su efectividad en el uso de herramientas lo convierten en una opción de primer nivel para aplicaciones que requieren un comportamiento agéntico robusto y una orquestación compleja de herramientas. La arquitectura MoE equilibra eficientemente los parámetros totales altos con parámetros activos manejables para la inferencia. Kimi K2, como modelo MoE, con un billón de parámetros totales pero solo 32 mil millones activos por inferencia 11, está explícitamente optimizado para "capacidades agénticas" y "uso avanzado de herramientas".11 Los modelos MoE están diseñados para ser computacionalmente eficientes al activar solo un subconjunto de expertos. El sólido rendimiento de Kimi K2 en las evaluaciones de uso de herramientas 11 a pesar de un recuento de parámetros activos relativamente más bajo en comparación con sus parámetros totales es notable. Esto sugiere que para tareas especializadas como el uso de herramientas, la "potencia" de un modelo no está determinada únicamente por su recuento máximo de parámetros, sino por la eficacia con la que su arquitectura y entrenamiento aprovechan esos parámetros para la tarea específica. Kimi K2 demuestra que la optimización dirigida dentro de un marco MoE puede producir capacidades de uso de herramientas altamente efectivas con mayor eficiencia de inferencia, lo que lo convierte en una opción convincente para los desarrolladores que priorizan tanto el rendimiento como la utilización de recursos en sistemas agénticos.

### **Modelos DeepSeek (DeepSeek V3 0324, R1 0528, R1, DeepSeek V3, TNG DeepSeek R1T2 Chimera, TNG DeepSeek R1T Chimera)**

La familia de modelos DeepSeek es ampliamente reconocida por su sólido rendimiento en tareas de codificación, matemáticas y razonamiento general. La documentación de la API de DeepSeek confirma el soporte general para la llamada a funciones en sus modelos.5

**DeepSeek V3 0324 (gratuito):** Este es un modelo de Mezcla de Expertos de 685B parámetros, con 262B tokens.7 Cuenta con una ventana de contexto de 33K tokens 7 y es gratuito en OpenRouter. En la clasificación de OpenRouter, ocupa una posición muy alta, siendo el tercer modelo más utilizado en la plataforma.15 Se describe como la última iteración del modelo de chat insignia de DeepSeek, superando a otros modelos de código abierto y rivalizando con los principales modelos de código cerrado.7

**DeepSeek R1 0528 (gratuito):** Este es un modelo MoE de 671B parámetros con 37B parámetros activos y una ventana de contexto de 164K tokens.7 También es gratuito en OpenRouter. Ocupa el noveno lugar en la clasificación general de OpenRouter.15 Se afirma que ofrece un "rendimiento a la par con OpenAI o1" 7 y que "¡soporta la llamada a herramientas nativa en OpenRouter\!".19 Los análisis independientes corroboran su sólido rendimiento, describiéndolo como un rendimiento "casi a nivel de Claude 4" y destacando su excelencia en matemáticas y codificación, a menudo clasificándose "justo detrás de lo mejor de OpenAI".16 Se informa que "maneja mejor las herramientas/llamadas a la API" con un "soporte mejorado para la llamada a funciones basada en JSON".16 Sin embargo, una advertencia crítica es que, a pesar de su alto rendimiento general y su soporte explícito para la llamada a funciones, un informe significativo de la comunidad destaca un "problema conocido" con la precisión de su llamada a funciones de múltiples turnos. Aunque la precisión de un solo turno es alta, "falla en la mayoría de los casos de evaluación BFCL\_v3\_MultiTurn de múltiples turnos, con una precisión tan baja como el 4-6%".22 Esto afecta gravemente su fiabilidad para flujos de trabajo agénticos complejos y encadenados.

**DeepSeek R1 (gratuito) y DeepSeek V3 (gratuito):** Estas son versiones anteriores de los modelos DeepSeek R1 0528 y DeepSeek V3 0324, respectivamente.7 Aunque soportan la llamada a funciones 5, generalmente se consideran menos potentes y refinados que sus contrapartes actualizadas.

**Modelos TNG DeepSeek Chimera (R1T2 Chimera, R1T Chimera) (gratuitos):** Estos modelos (R1T2 Chimera: 14.3B tokens, 164K contexto; R1T Chimera: 6.67B tokens, 164K contexto) se crean fusionando varios puntos de control de DeepSeek.7 Su objetivo es equilibrar el rendimiento del razonamiento con la eficiencia. Si bien se derivan de modelos DeepSeek que soportan la llamada a funciones, no hay comentarios específicos de la comunidad ni datos de rendimiento detallados disponibles en las fuentes proporcionadas con respecto a su fiabilidad o matices

*particulares* en la llamada a funciones. Se asume que heredan las capacidades base de DeepSeek, potencialmente con limitaciones similares de múltiples turnos que R1 0528\.

En resumen, DeepSeek V3 0324 y R1 0528 son modelos de propósito general innegablemente potentes, que ocupan un lugar destacado en la clasificación de OpenRouter y demuestran un sólido rendimiento en diversas evaluaciones. DeepSeek R1 0528 ofrece soporte explícito para la llamada a herramientas. Sin embargo, el problema documentado de fiabilidad en la llamada a funciones de múltiples turnos para R1 0528 es una limitación crítica para los desarrolladores que construyen agentes complejos y con estado. Los otros modelos DeepSeek y TNG Chimera están menos validados exhaustivamente para el rendimiento específico del uso de herramientas.

La observación de que DeepSeek R1 0528 es elogiado por su inteligencia general y soporta explícitamente la llamada a herramientas 16, pero un informe de la comunidad revela que, si bien su llamada a funciones de un solo turno es precisa, su rendimiento en múltiples turnos es extremadamente deficiente (4-6% de precisión en la evaluación BFCL\_v3\_MultiTurn) 22, destaca una distinción crucial. Un modelo puede

*soportar técnicamente* la llamada a funciones e incluso funcionar bien en instancias aisladas, pero carecer del razonamiento robusto subyacente, la memoria o la gestión de estado necesarios para llamadas a herramientas secuenciales e interdependientes. Para los desarrolladores, esto significa que simplemente verificar el "soporte para la llamada a funciones" es insuficiente para aplicaciones agénticas complejas. La verdadera "potencia" en el uso de herramientas para agentes avanzados requiere un rendimiento fiable en múltiples turnos, donde el modelo pueda encadenar acciones y razonar sobre los efectos acumulativos de las salidas de las herramientas. Esto exige una evaluación más profunda de las capacidades de un modelo más allá de la simple compatibilidad con la API, lo que podría requerir pruebas personalizadas para escenarios específicos de múltiples turnos.

### **OpenRouter: Cypher Alpha (gratuito)**

Cypher Alpha, un modelo proporcionado por OpenRouter (cuyo desarrollador permanece sin revelar, lo que genera especulaciones de que podría ser un modelo inédito de un actor importante 1), ofrece una impresionante ventana de contexto de 1 millón de tokens.1 Esta capacidad lo hace ideal para tareas de IA a gran escala y puede generar hasta 10,000 tokens por respuesta.1 Es completamente gratuito en OpenRouter.1 Una de sus características clave es el "soporte incorporado para la llamada a herramientas, lo que le permite interactuar con APIs y herramientas externas".1 Se describe como un "modelo versátil" y una "potencia gratuita".1

Las discusiones de la comunidad, como las de un blog de Apidog, confirman su utilidad para la "experimentación de IA" debido a su acceso gratuito y sus capacidades.1 Su gran ventana de contexto lo hace excelente para procesar y resumir datos, y es adecuado para la generación de código y la creación de contenido.1 Una consideración importante es que las indicaciones y las finalizaciones para Cypher Alpha son registradas por el creador del modelo y "pueden ser utilizadas para el entrenamiento".25 Este es un compromiso a cambio de su acceso gratuito.

Cypher Alpha es una opción gratuita singularmente potente, distinguida principalmente por su enorme ventana de contexto de 1 millón de tokens combinada con capacidades nativas de llamada a herramientas. Esto lo hace excepcionalmente adecuado para tareas agénticas de contexto largo, como el análisis de documentos extensos o conjuntos de datos complejos para informar la selección y ejecución de herramientas. Si bien su clasificación de inteligencia general no se encuentra en la tabla de clasificación principal de OpenRouter, sus características especializadas y su gratuidad lo convierten en un activo altamente valioso para los desarrolladores que estén dispuestos a aceptar la política de registro de datos. La característica más destacada de Cypher Alpha es su ventana de contexto de 1 millón de tokens.1 Una ventana de contexto grande permite más tokens de entrada, lo que es beneficioso para documentos extensos. Para la llamada a funciones, esto se traduce en un aumento significativo de la "potencia" para flujos de trabajo agénticos complejos. Significa que el modelo puede ingerir y retener esquemas de herramientas más detallados y numerosos, un historial conversacional extenso de múltiples turnos, los resultados de muchas llamadas a herramientas anteriores y grandes conjuntos de datos o documentos que deben analizarse antes de la selección de herramientas. Esta capacidad de retención de información extensa mejora directamente la habilidad del modelo para tomar decisiones más informadas sobre

*qué* herramienta llamar, *cómo* llamarla y *cómo interpretar* sus resultados en una tarea compleja y evolutiva, multiplicando así su "potencia" efectiva para aplicaciones sofisticadas de uso de herramientas.

### **Modelos Mistral (Mistral Small 3.2 24B, Devstral Small)**

Mistral ofrece dos modelos gratuitos altamente capaces para la llamada a funciones.

**Mistral Small 3.2 24B (gratuito):** Este modelo de MistralAI tiene 24B parámetros 12 con una ventana de contexto de 96K tokens.8 Es de uso gratuito en OpenRouter.8 Sus características incluyen optimización para "seguir instrucciones, reducir repeticiones y mejorar la llamada a funciones" en comparación con su predecesor.12 Soporta entradas de imagen y texto, salidas estructuradas y llamada a funciones/herramientas.12 Demuestra un sólido rendimiento en evaluaciones de codificación (HumanEval+, MBPP), STEM (MMLU, MATH, GPQA) y visión.12 En cuanto a la llamada a funciones, Mistral Small 3.2 se destaca por tener una plantilla de llamada a funciones "más robusta" 20 y soporta características avanzadas como

tool\_choice y parallel\_tool\_calls.23

**Mistral: Devstral Small (gratuito):** Desarrollado por MistralAI en colaboración con All Hands AI, este es un modelo de código abierto de 24B parámetros 13 con una ventana de contexto de 128K tokens.13 Es gratuito en OpenRouter 8 y se publica bajo la licencia permisiva Apache 2.0.21 Devstral Small 1.1 está "específicamente diseñado para agentes de ingeniería de software" y "optimizado para flujos de trabajo de codificación agéntica".13 Destaca en tareas como la exploración de bases de código, ediciones de múltiples archivos y la integración en agentes de desarrollo autónomos.13 En cuanto a la llamada a funciones, soporta explícitamente el "formato de llamada a funciones estilo Mistral y formatos de salida XML".13 Un indicador clave de rendimiento es su logro del 53.6% en SWE-Bench Verified, "superando a todos los demás modelos de código abierto en esta evaluación".13 Para el rendimiento agéntico, Devstral Small se considera "equivalente a ChatGPT 4.1" 21 y "excelente cuando se combina con OpenHands".24

Mistral Small 3.2 24B es un modelo robusto de propósito general con capacidades de llamada a funciones explícitamente mejoradas y fiables, adecuado para una amplia gama de tareas. Devstral Small es una opción sobresaliente para tareas agénticas de codificación *especializadas*. Su optimización dirigida a flujos de trabajo de ingeniería de software, combinada con un rendimiento de vanguardia en evaluaciones de codificación como SWE-Bench, lo hace excepcionalmente potente para el uso de herramientas dentro de ese dominio. La licencia Apache 2.0 mejora aún más su utilidad para el desarrollo de código abierto. La existencia de un modelo de propósito general (Mistral Small 3.2) y uno especializado (Devstral Small) de Mistral que soportan la llamada a funciones 12 demuestra que Devstral Small, a pesar de tener parámetros similares a Mistral Small 3.2, está "específicamente diseñado para agentes de ingeniería de software" y logra resultados de vanguardia en SWE-Bench Verified.13 Esto indica que un modelo con un enfoque de dominio específico puede superar a los modelos más generales dentro de su nicho. Para los desarrolladores, esto pone de manifiesto que la "potencia" en la llamada a funciones no se trata únicamente de inteligencia general, sino también de la capacidad del modelo para comprender y ejecutar con precisión patrones de uso de herramientas relevantes para un dominio particular. Un modelo ajustado para un área de aplicación específica (por ejemplo, codificación, investigación legal, diagnóstico médico) puede ser significativamente más efectivo y fiable en sus interacciones con herramientas dentro de ese dominio, incluso si no es el LLM más grande o más capaz en general. Esto fomenta la selección de modelos en función de su alineación con la tarea agéntica específica.

### **Google: Modelos Gemma (Gemma 3n 2B, Gemma 3n 4B) (gratuitos)**

Google ofrece dos modelos Gemma gratuitos en OpenRouter: Gemma 3n 2B y Gemma 3n 4B.8 Ambos tienen una ventana de contexto de 8.192K tokens 8 y están disponibles sin costo.8 La documentación oficial de Google confirma que "la llamada a funciones es compatible con Gemma 3" 14, y soporta tanto la llamada a funciones paralela como la composicional.6 La documentación recomienda variantes más grandes de Gemma 3 (27B para el mejor rendimiento, 12B para un rendimiento equilibrado) para obtener resultados óptimos.14

Aunque la documentación general de Gemma 3 confirma las capacidades de llamada a funciones, no hay informes específicos de la comunidad ni evaluaciones de rendimiento detalladas disponibles en las fuentes proporcionadas para las *versiones gratuitas de OpenRouter* (Gemma 3n 2B, Gemma 3n 4B) con respecto a su fiabilidad o precisión en la llamada a funciones en el mundo real. Dado su menor recuento de parámetros y su ventana de contexto limitada en comparación con otros modelos gratuitos, su utilidad práctica para tareas agénticas complejas es probablemente restringida.

Estos modelos Gemma, aunque soportan la llamada a funciones y son gratuitos, representan el extremo inferior del espectro de potencia para escenarios complejos de uso de herramientas. Su menor tamaño de parámetros y su ventana de contexto más limitada sugieren que son más adecuados para llamadas a herramientas muy simples y de un solo paso, o para aplicaciones que operan bajo estrictas restricciones de recursos donde los modelos más grandes no son factibles. La disponibilidad de Gemma 3n 2B y 4B como modelos gratuitos en OpenRouter que soportan la llamada a funciones 8, a pesar de sus recuentos de parámetros relativamente pequeños (2B, 4B) y una ventana de contexto limitada (8.192K) 8, ilustra una compensación común dentro de los niveles gratuitos. Si bien la accesibilidad es alta, la "potencia" para tareas complejas o de llamada a funciones de múltiples turnos está inherentemente limitada por la escala del modelo. Es probable que estos modelos sean adecuados para interacciones básicas y restringidas con herramientas donde la solicitud y el esquema de la herramienta son simples, pero tendrían dificultades con el razonamiento matizado y el contexto extenso requeridos para flujos de trabajo agénticos sofisticados. Esto significa que los desarrolladores deben alinear la complejidad de su tarea con las limitaciones de escala inherentes del modelo, incluso cuando el servicio es gratuito.

## **Lista Clasificada: Modelos Gratuitos de OpenRouter para la Llamada a Funciones (De Más a Menos Potente)**

La siguiente tabla presenta la clasificación de los modelos gratuitos de OpenRouter que soportan la llamada a funciones, ordenados de los más potentes a los menos potentes, con justificaciones concisas para cada posición.

### **Tabla 2: Lista Clasificada de Modelos Gratuitos de OpenRouter para la Llamada a Funciones**

| Clasificación | Modelo | Fortalezas Clave para la Llamada a Funciones | Limitaciones/Consideraciones Clave |
| :---- | :---- | :---- | :---- |
| 1º | Google: Gemini 2.0 Flash Experimental | Equilibrio excepcional de inteligencia general, mejoras explícitas en llamada a funciones, ventana de contexto masiva (1.05M tokens), fiabilidad y velocidad validadas por la comunidad para experiencias agénticas robustas. 10 | Experimental, puede estar sujeto a límites de tasa por Google. 10 |
| 2º | MoonshotAI: Kimi K2 | Optimizado explícitamente para uso avanzado de herramientas y capacidades agénticas, rendimiento sólido en evaluaciones especializadas de uso de herramientas, arquitectura MoE eficiente. 7 | Licencia MIT modificada con cláusula de "éxito comercial" para display de marca. 18 |
| 3º | DeepSeek: DeepSeek V3 0324 | Modelo de propósito general muy potente, alta clasificación en OpenRouter, rivaliza con modelos de código cerrado, soporte general para llamada a funciones. 5 | Ventana de contexto más pequeña (33K) en comparación con los modelos de primer nivel. 7 |
| 4º | Mistral: Devstral Small | Excepcional especialización para flujos de trabajo agénticos de codificación, rendimiento de vanguardia en SWE-Bench Verified, equivalente a ChatGPT 4.1 para rendimiento agéntico, licencia Apache 2.0. 13 | Potencia óptima principalmente para tareas de codificación. 13 |
| 5º | OpenRouter: Cypher Alpha | Ventana de contexto sin precedentes (1M tokens) ideal para tareas agénticas de contexto largo, soporte nativo para llamada a herramientas, completamente gratuito. 1 | Origen no revelado, las indicaciones y finalizaciones pueden ser registradas para entrenamiento. 25 |
| 6º | DeepSeek: R1 0528 | Generalmente muy potente, rendimiento casi a nivel de Claude 4, soporte explícito para llamada a herramientas nativa. 7 | Problemas documentados de precisión en la llamada a funciones de múltiples turnos (4-6% de precisión). 22 |
| 7º | Mistral: Mistral Small 3.2 24B | Modelo robusto de propósito general con llamada a funciones mejorada y robusta, rendimiento sólido en diversas evaluaciones, soporta entradas de imagen y texto. 8 | Menos especializado para tareas agénticas complejas que Devstral Small. 13 |
| 8º | DeepSeek: R1 | Versión anterior de R1 0528, soporta llamada a funciones, pero menos refinado y performante que su sucesor. 5 | Menor rendimiento general y manejo de herramientas en comparación con R1 0528\. 16 |
| 9º | DeepSeek: DeepSeek V3 | Versión anterior de DeepSeek V3 0324, soporta llamada a funciones, pero menos potente que su sucesor. 5 | Menor capacidad general en comparación con DeepSeek V3 0324\. 7 |
| 10º | TNG: DeepSeek R1T2 Chimera | Modelo fusionado que aprovecha componentes de DeepSeek, ofrece un razonamiento sólido y eficiencia. 7 | Validación comunitaria limitada para el rendimiento específico de la llamada a funciones. 7 |
| 11º | TNG: DeepSeek R1T Chimera | Otro modelo DeepSeek fusionado, optimizado para la generación general de texto. 7 | Validación comunitaria limitada para el rendimiento específico de la llamada a funciones. 7 |
| 12º | Google: Gemma 3n 4B | Soporta llamada a funciones y es gratuito. 8 | Modelo más pequeño (4B parámetros) con ventana de contexto limitada (8.192K), potencia reducida para tareas agénticas complejas. 8 |
| 13º | Google: Gemma 3n 2B | El modelo Gemma gratuito más pequeño que soporta llamada a funciones. 8 | Muy limitado en tamaño (2B parámetros) y ventana de contexto (8.192K), adecuado solo para tareas muy básicas y restringidas. 8 |

### **Justificaciones Detalladas para la Clasificación**

1. **Google: Gemini 2.0 Flash Experimental:** Este modelo se clasifica en la primera posición debido a su excepcional equilibrio entre inteligencia general (ocupa el segundo lugar en OpenRouter por uso de tokens 15), mejoras explícitas en la llamada a funciones 10, y una ventana de contexto masiva de 1.05 millones de tokens.10 Crucialmente, recibe una retroalimentación abrumadoramente positiva de la comunidad con respecto a su fiabilidad práctica, velocidad y rentabilidad para experiencias agénticas robustas 17, lo que lo convierte en una potencia versátil y fiable para diversas aplicaciones de uso de herramientas.  
2. **MoonshotAI: Kimi K2:** Obtiene su alta clasificación gracias a su optimización explícita para el "uso avanzado de herramientas" y las "capacidades agénticas" 11, validado por un sólido rendimiento en evaluaciones especializadas de uso de herramientas (Tau2, AceBench). Su arquitectura de Mezcla de Expertos (1T de parámetros totales, 32B activos 11) ofrece eficientemente una alta capacidad en su dominio especializado, y los informes de la comunidad confirman su eficacia en el seguimiento de instrucciones y el uso de herramientas.18  
3. **DeepSeek: DeepSeek V3 0324:** Un modelo de propósito general muy potente, clasificado en tercer lugar en OpenRouter 15 y destacado por rivalizar con los principales modelos de código cerrado.7 Aunque las evaluaciones específicas de llamada a herramientas son menos detalladas que las de Kimi K2, su alta inteligencia general y el soporte confirmado para la llamada a funciones de DeepSeek 5 lo convierten en una opción robusta, probablemente destacando en escenarios de un solo turno y de múltiples turnos menos complejos, sin los problemas explícitos de múltiples turnos reportados para R1 0528\.  
4. **Mistral: Devstral Small:** Se posiciona en un lugar destacado debido a su excepcional especialización para flujos de trabajo agénticos *específicos de codificación*. Su rendimiento de vanguardia en SWE-Bench Verified (53.6% 13) y su equivalencia a "ChatGPT 4.1" para el rendimiento agéntico 21 demuestran sus capacidades robustas y fiables de uso de herramientas dentro de su nicho. La licencia Apache 2.0 es una ventaja práctica significativa para los desarrolladores.21  
5. **OpenRouter: Cypher Alpha:** Una opción única y potente, distinguida principalmente por su ventana de contexto sin precedentes de 1 millón de tokens 1 combinada con soporte nativo para la llamada a herramientas.1 Esto lo hace idealmente adecuado para tareas agénticas altamente complejas y de contexto largo que requieren procesar información extensa para la selección y ejecución de herramientas. Su origen "misterioso" y la política de registro de datos 25 son consideraciones importantes.  
6. **DeepSeek: R1 0528:** Aunque generalmente muy potente ("casi a nivel de Claude 4" 16) y con soporte nativo para la llamada a herramientas 19, su utilidad práctica para flujos de trabajo agénticos complejos se ve significativamente obstaculizada por informes documentados de la comunidad sobre una baja precisión en la llamada a funciones de múltiples turnos.22 Esta limitación crítica para el uso encadenado de herramientas lo sitúa por debajo de los modelos con un rendimiento más robusto en múltiples turnos, a pesar de sus altas evaluaciones generales.  
7. **Mistral: Mistral Small 3.2 24B:** Un modelo de propósito general sólido con "llamada a funciones mejorada" 12 y un rendimiento robusto en diversas evaluaciones.12 Ofrece una llamada a funciones fiable para una amplia gama de tareas, sirviendo como una opción sólida en general, aunque no tan especializado para la codificación agéntica como Devstral Small.  
8. **DeepSeek: R1:** Una versión anterior de R1 0528\.7 Aunque soporta la llamada a funciones 5, generalmente es menos performante y refinado que su contraparte actualizada, especialmente en áreas como el razonamiento y el manejo de herramientas.16  
9. **DeepSeek: DeepSeek V3:** Una versión anterior de DeepSeek V3 0324\.7 Soporta la llamada a funciones 5 pero es superado por la variante 0324 más potente, ofreciendo menos capacidad general.  
10. **TNG: DeepSeek R1T2 Chimera:** Un modelo fusionado que aprovecha componentes de DeepSeek.7 Ofrece un razonamiento sólido y eficiencia. Si bien es probable que herede el soporte para la llamada a funciones, la validación comunitaria específica para su fiabilidad en el uso de herramientas es menos disponible en comparación con los modelos DeepSeek centrales, lo que lo sitúa más abajo debido a un rendimiento menos confirmado para la consulta específica.  
11. **TNG: DeepSeek R1T Chimera:** Otro modelo DeepSeek fusionado 7, optimizado para la generación general de texto. Similar a R1T2 Chimera, la retroalimentación explícita de la comunidad sobre su rendimiento en la llamada a funciones es limitada, lo que lleva a una clasificación más baja para este caso de uso específico.  
12. **Google: Gemma 3n 4B:** Soporta la llamada a funciones 6 y es gratuito en OpenRouter.8 Sin embargo, como modelo más pequeño (4B parámetros) con una ventana de contexto limitada (8.192K), su "potencia" general para escenarios complejos o de múltiples pasos de uso de herramientas se espera que sea significativamente menor que la de los modelos más grandes y especializados. Es adecuado para tareas muy simples y restringidas.  
13. **Google: Gemma 3n 2B:** El modelo Gemma gratuito más pequeño (2B parámetros) que soporta la llamada a funciones.6 Su tamaño limitado y su ventana de contexto lo hacen el menos potente para tareas agénticas exigentes, siendo el más adecuado para interacciones con herramientas muy básicas y de un solo paso o aplicaciones con recursos altamente restringidos.

## **Consideraciones Clave para la Implementación y el Uso**

La selección de un modelo LLM gratuito con capacidad de llamada a funciones en OpenRouter requiere una evaluación cuidadosa de varios factores prácticos para garantizar que el modelo se alinee con los requisitos específicos de la aplicación.

### **Consejos Prácticos para la Selección de un Modelo**

* **Complejidad de la Tarea:** Para llamadas a herramientas simples y de un solo paso (por ejemplo, recuperar un único dato), muchos modelos serán suficientes. Para flujos de trabajo agénticos complejos y de múltiples turnos que requieren el uso secuencial de herramientas y un razonamiento robusto sobre los resultados intermedios, se deben priorizar los modelos optimizados explícitamente para el uso de herramientas y con fiabilidad probada en múltiples turnos (por ejemplo, Kimi K2, Mistral Devstral Small, Gemini 2.0 Flash Experimental).  
* **Requisitos de la Ventana de Contexto:** Las aplicaciones que manejan documentos muy largos, historiales conversacionales extensos o que requieren que el modelo recuerde muchas salidas de herramientas anteriores se beneficiarán enormemente de los modelos con grandes ventanas de contexto, como Cypher Alpha (1M tokens) o Gemini 2.0 Flash Experimental (1.05M tokens).1 La capacidad de una ventana de contexto extensa para retener información detallada de esquemas de herramientas, historial de conversaciones y resultados de llamadas anteriores multiplica la "potencia" efectiva del modelo para la toma de decisiones informadas en tareas complejas de uso de herramientas.  
* **Especialización del Dominio:** Para aplicaciones específicas como la generación de código o los agentes de ingeniería de software, modelos como Mistral Devstral Small ofrecen una ventaja significativa debido a su entrenamiento dirigido y su rendimiento superior en esos dominios.13 Esto resalta que la "potencia" en la llamada a funciones no es solo una cuestión de inteligencia general, sino también de la capacidad del modelo para comprender y ejecutar patrones de uso de herramientas relevantes para un dominio particular.  
* **Fiabilidad vs. Evaluaciones:** Siempre se deben contrastar las evaluaciones oficiales con la retroalimentación de la comunidad sobre la fiabilidad en el mundo real. Como se observa con los problemas de llamada a funciones de múltiples turnos de DeepSeek R1 0528 22, una alta inteligencia general no garantiza un rendimiento robusto para todos los aspectos del uso de herramientas. Se recomienda encarecidamente realizar pruebas prácticas para su caso de uso específico.  
* **Privacidad y Registro de Datos:** Es fundamental ser consciente de las políticas de datos asociadas con los modelos gratuitos. Por ejemplo, Cypher Alpha registra las indicaciones y las finalizaciones con fines de entrenamiento.25 Esta es una consideración crucial para las aplicaciones que manejan información sensible o propietaria.  
* **Aprovechamiento de la API de OpenRouter:** Es aconsejable utilizar la API estandarizada de OpenRouter para facilitar la integración y la posibilidad de recurrir automáticamente a otros proveedores, lo que puede mejorar la fiabilidad.2

La disponibilidad de modelos "gratuitos" en OpenRouter, aunque atractiva por la ausencia de costos monetarios directos por token 7, implica consideraciones adicionales. Esta aparente gratuidad a menudo conlleva compromisos o "costos ocultos". Por ejemplo, la política de registro de datos de Cypher Alpha para fines de entrenamiento 25 es un ejemplo claro de cómo la falta de un costo monetario directo puede traducirse en una compensación en términos de privacidad de datos o control sobre el uso de la información. Además, como se ha visto con los modelos Gemma más pequeños 8, la escala limitada de algunos modelos gratuitos puede restringir inherentemente su "potencia" para tareas complejas o de múltiples turnos, lo que significa que el "costo" puede ser una menor capacidad o la necesidad de simplificar la complejidad de la tarea. Por lo tanto, los desarrolladores deben evaluar cuidadosamente estos factores no monetarios al seleccionar modelos gratuitos para asegurarse de que se alineen con sus requisitos de rendimiento, privacidad y escalabilidad.

## **Conclusiones y Recomendaciones**

El panorama de los LLMs gratuitos con capacidades de llamada a funciones en OpenRouter es dinámico y ofrece opciones robustas para una amplia gama de aplicaciones. La selección del modelo más adecuado depende en gran medida de los requisitos específicos del caso de uso, la tolerancia a las limitaciones y la complejidad de las tareas agénticas a realizar.

**Recomendaciones Clave:**

* **Para Agentes Versátiles y de Alto Rendimiento:** **Google Gemini 2.0 Flash Experimental** es la principal recomendación. Su combinación de una ventana de contexto masiva, capacidades agénticas mejoradas y una sólida validación comunitaria de su fiabilidad lo convierten en una opción inigualable para la mayoría de los casos de uso que requieren llamadas a funciones robustas y rápidas.  
* **Para Agentes Altamente Optimizados para el Uso de Herramientas:** **MoonshotAI Kimi K2** es una elección sobresaliente. Su diseño y entrenamiento específicos para el uso de herramientas y las capacidades agénticas lo hacen excepcionalmente eficaz en la orquestación de tareas complejas, especialmente donde la precisión en la llamada a funciones es crítica.  
* **Para Agentes de Codificación Especializados:** **Mistral Devstral Small** es el modelo preferido. Su rendimiento de vanguardia en evaluaciones de ingeniería de software y su optimización para flujos de trabajo de codificación agéntica lo hacen indispensable para desarrolladores que construyen herramientas de automatización de código.  
* **Para Tareas de Contexto Extremadamente Largo:** **OpenRouter Cypher Alpha** es una opción única y potente. Su ventana de contexto de 1 millón de tokens lo hace ideal para procesar y razonar sobre volúmenes masivos de datos antes de realizar llamadas a herramientas, siempre que la política de registro de datos sea aceptable.

**Consideraciones Críticas Finales:**

* **La Fiabilidad en Múltiples Turnos es Clave:** Como lo demuestra el caso de DeepSeek R1 0528, el soporte explícito para la llamada a funciones no garantiza un rendimiento fiable en escenarios de múltiples turnos. Para aplicaciones agénticas complejas, es imperativo probar la capacidad del modelo para encadenar llamadas a herramientas y mantener el estado de manera consistente.  
* **El "Gratuito" Implica Compromisos:** Los modelos gratuitos pueden venir con políticas de uso de datos (como el registro para entrenamiento) o limitaciones inherentes en escala y capacidad que deben ser consideradas cuidadosamente en el contexto de la privacidad y la complejidad de la aplicación.  
* **La Especialización Aumenta la Potencia:** La "potencia" de un modelo para la llamada a funciones no es solo una medida de inteligencia general, sino también de su alineación con el dominio de la tarea. Los modelos optimizados para nichos específicos a menudo superarán a los modelos de propósito general en esos contextos.

En última instancia, la plataforma OpenRouter democratiza el acceso a capacidades avanzadas de IA, permitiendo la experimentación y el desarrollo de agentes inteligentes sin barreras de costos iniciales. Sin embargo, una comprensión matizada de las fortalezas, debilidades y compromisos de cada modelo, validada por la experiencia de la comunidad, es esencial para una implementación exitosa.

#### **Fuentes citadas**

1. Cypher Alpha: What's the Free Mysterious OpenRouter API? \- Apidog, acceso: julio 20, 2025, [https://apidog.com/blog/cypher-alpha/](https://apidog.com/blog/cypher-alpha/)  
2. Comparison: TensorZero vs. OpenRouter, acceso: julio 20, 2025, [https://www.tensorzero.com/docs/comparison/openrouter/](https://www.tensorzero.com/docs/comparison/openrouter/)  
3. How to Use LLMs for Free ? \- Apidog, acceso: julio 20, 2025, [https://apidog.com/blog/use-llms-for-free/](https://apidog.com/blog/use-llms-for-free/)  
4. Tool & Function Calling | Use Tools with OpenRouter | OpenRouter ..., acceso: julio 20, 2025, [https://openrouter.ai/docs/features/tool-calling](https://openrouter.ai/docs/features/tool-calling)  
5. Function Calling \- DeepSeek API Docs, acceso: julio 20, 2025, [https://api-docs.deepseek.com/guides/function\_calling](https://api-docs.deepseek.com/guides/function_calling)  
6. Function calling with the Gemini API | Google AI for Developers, acceso: julio 20, 2025, [https://ai.google.dev/gemini-api/docs/function-calling](https://ai.google.dev/gemini-api/docs/function-calling)  
7. Models: 'free' \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/models/?q=free](https://openrouter.ai/models/?q=free)  
8. OpenRouter Model Price Comparison, acceso: julio 20, 2025, [https://compare-openrouter-models.pages.dev/](https://compare-openrouter-models.pages.dev/)  
9. Models: 'morph-v3-fast' \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/)](https://openrouter.ai/\))  
10. Gemini 2.0 Flash Experimental (free) \- API, Providers, Stats \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/google/gemini-2.0-flash-exp:free](https://openrouter.ai/google/gemini-2.0-flash-exp:free)  
11. Kimi K2 \- API, Providers, Stats \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/moonshotai/kimi-k2](https://openrouter.ai/moonshotai/kimi-k2)  
12. Mistral Small 3.2 24B (free) \- API, Providers, Stats \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/mistralai/mistral-small-3.2-24b-instruct:free](https://openrouter.ai/mistralai/mistral-small-3.2-24b-instruct:free)  
13. Devstral Small 1.1 \- API, Providers, Stats \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/mistralai/devstral-small](https://openrouter.ai/mistralai/devstral-small)  
14. Function calling with Gemma | Google AI for Developers \- Gemini API, acceso: julio 20, 2025, [https://ai.google.dev/gemma/docs/capabilities/function-calling](https://ai.google.dev/gemma/docs/capabilities/function-calling)  
15. LLM Rankings \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/rankings](https://openrouter.ai/rankings)  
16. DeepSeek's New R1–0528: Performance Analysis and Benchmark Comparisons \- Medium, acceso: julio 20, 2025, [https://medium.com/@leucopsis/deepseeks-new-r1-0528-performance-analysis-and-benchmark-comparisons-6440eac858d6](https://medium.com/@leucopsis/deepseeks-new-r1-0528-performance-analysis-and-benchmark-comparisons-6440eac858d6)  
17. Gemini Flash 2.0 is top model on OpenRouter : r/Bard \- Reddit, acceso: julio 20, 2025, [https://www.reddit.com/r/Bard/comments/1j860m1/gemini\_flash\_20\_is\_top\_model\_on\_openrouter/](https://www.reddit.com/r/Bard/comments/1j860m1/gemini_flash_20_is_top_model_on_openrouter/)  
18. moonshotai/Kimi-K2-Instruct (and Kimi-K2-Base) : r/LocalLLaMA \- Reddit, acceso: julio 20, 2025, [https://www.reddit.com/r/LocalLLaMA/comments/1lx8xdm/moonshotaikimik2instruct\_and\_kimik2base/](https://www.reddit.com/r/LocalLLaMA/comments/1lx8xdm/moonshotaikimik2instruct_and_kimik2base/)  
19. The new DeepSeek R1 0528 now supports native tool calling on OpenRouter\! \- Reddit, acceso: julio 20, 2025, [https://www.reddit.com/r/DeepSeek/comments/1l84cx3/the\_new\_deepseek\_r1\_0528\_now\_supports\_native\_tool/](https://www.reddit.com/r/DeepSeek/comments/1l84cx3/the_new_deepseek_r1_0528_now_supports_native_tool/)  
20. mistralai/Mistral-Small-3.2-24B-Instruct-2506 · Hugging Face : r/LocalLLaMA \- Reddit, acceso: julio 20, 2025, [https://www.reddit.com/r/LocalLLaMA/comments/1lg7vuc/mistralaimistralsmall3224binstruct2506\_hugging/](https://www.reddit.com/r/LocalLLaMA/comments/1lg7vuc/mistralaimistralsmall3224binstruct2506_hugging/)  
21. mistralai/Devstral-Small-2507 : r/LocalLLaMA \- Reddit, acceso: julio 20, 2025, [https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/mistralaidevstralsmall2507/](https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/mistralaidevstralsmall2507/)  
22. Is DeepSeek R1-0528 function call chat template supported BFCL multi turn benchmark?, acceso: julio 20, 2025, [https://discuss.vllm.ai/t/is-deepseek-r1-0528-function-call-chat-template-supported-bfcl-multi-turn-benchmark/1039](https://discuss.vllm.ai/t/is-deepseek-r1-0528-function-call-chat-template-supported-bfcl-multi-turn-benchmark/1039)  
23. Function calling \- Mistral AI Documentation, acceso: julio 20, 2025, [https://docs.mistral.ai/capabilities/function\_calling/](https://docs.mistral.ai/capabilities/function_calling/)  
24. Upgrading agentic coding capabilities with the new Devstral models \- Mistral AI, acceso: julio 20, 2025, [https://mistral.ai/news/devstral-2507](https://mistral.ai/news/devstral-2507)  
25. New Stealth Model: "Cypher Alpha" \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/announcements/new-stealth-model-cypher-alpha](https://openrouter.ai/announcements/new-stealth-model-cypher-alpha)  
26. Cypher Alpha \- API, Providers, Stats \- OpenRouter, acceso: julio 20, 2025, [https://openrouter.ai/openrouter/cypher-alpha:free](https://openrouter.ai/openrouter/cypher-alpha:free)